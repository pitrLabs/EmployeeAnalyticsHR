{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-02T16:53:34.751374Z",
     "start_time": "2025-09-02T16:53:34.552700Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import random\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from decouple import config\n",
    "from faker import Faker\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Promotion = ongoing\n",
    "# Resignation = ongoing\n",
    "# Turnover = done\n",
    "\n",
    "\n",
    "class HRAnalyticsModel:\n",
    "    def __init__(self):\n",
    "        self.conn = psycopg2.connect(host=config(\"PSQL_HOST2\"),\n",
    "                                     database=config(\"PSQL_DB2\"),\n",
    "                                     user=config(\"PSQL_USER2\"),\n",
    "                                     password=config(\"PSQL_PASS2\"),\n",
    "                                     port=config(\"PSQL_PORT2\"))\n",
    "\n",
    "        self.attendance_df = self.load_attendance()\n",
    "        self.departments_df = self.load_departments()\n",
    "        self.employees_df = self.load_employees()\n",
    "        self.performance_df = self.load_performance()\n",
    "        self.training_df = self.load_training()\n",
    "\n",
    "\n",
    "    def load_attendance(self):\n",
    "        query = \"\"\"\n",
    "            SELECT attendance_id, employee_id, date, status, hours_worked\n",
    "            FROM s_attendance;\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.conn)\n",
    "    \n",
    "    \n",
    "    def load_departments(self):\n",
    "        query = \"\"\"\n",
    "            SELECT department_id, department_name, location, budget\n",
    "            FROM s_departments;\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.conn)\n",
    "    \n",
    "    \n",
    "    def load_employees(self):\n",
    "        query = \"\"\"\n",
    "            SELECT employee_id, first_name, last_name, department_id, job_title, hire_date, manager_id, status, salary\n",
    "            FROM s_employees;\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.conn)\n",
    "    \n",
    "    \n",
    "    def load_performance(self):\n",
    "        query = \"\"\"\n",
    "            SELECT performance_id, employee_id, review_date, rating, reviewer_id\n",
    "            FROM s_performance;\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.conn)\n",
    "    \n",
    "    \n",
    "    def load_training(self):\n",
    "        query = \"\"\"\n",
    "            SELECT training_id, employee_id, training_name, category, score, completion_date\n",
    "            FROM s_training;\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.conn)\n",
    "\n",
    "    \n",
    "    \"\"\"Analytics\"\"\"\n",
    "    def calculate_turnover_rate(self):\n",
    "        total_employees = len(self.employees_df)\n",
    "        departed = len(self.employees_df[self.employees_df['status'] != 'active'])\n",
    "        turnover_rate = (departed / total_employees) * 100 if total_employees > 0 else 0\n",
    "        \n",
    "        return round(turnover_rate, 2)\n",
    "    \n",
    "    \n",
    "    def analyze_department_performance(self):\n",
    "        merged_df = pd.merge(self.performance_df,\n",
    "                             self.employees_df,\n",
    "                             on='employee_id')\n",
    "        merged_df = pd.merge(merged_df,\n",
    "                             self.departments_df,\n",
    "                             on='department_id')\n",
    "    \n",
    "        dept_performance = (merged_df\n",
    "                            .groupby('department_name')['rating']\n",
    "                            .agg(['mean', 'count', 'std', 'min', 'max'])\n",
    "                            .round(2))\n",
    "    \n",
    "        return dept_performance.reset_index()\n",
    "\n",
    "    \n",
    "    def attendance_analysis(self):\n",
    "        analysis = {\n",
    "            'total_days_recorded': len(self.attendance_df),\n",
    "            'present_days': len(self.attendance_df[self.attendance_df['status'] == 'present']),\n",
    "            'absent_days': len(self.attendance_df[self.attendance_df['status'] == 'absent']),\n",
    "            'late_days': len(self.attendance_df[self.attendance_df['status'] == 'late']),\n",
    "            'average_hours_worked': round(self.attendance_df['hours_worked'].mean(), 2),\n",
    "            'attendance_rate': round((len(self.attendance_df[self.attendance_df['status'] == 'present']) /\n",
    "                                      len(self.attendance_df)) * 100, 2)\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "\n",
    "    def salary_analysis(self):\n",
    "        merged_df = pd.merge(self.employees_df,\n",
    "                             self.departments_df,\n",
    "                             on='department_id')\n",
    "    \n",
    "        salary_stats = (merged_df\n",
    "                        .groupby('department_name')['salary']\n",
    "                        .agg([('avg_salary_million', lambda x: round(x.mean() / 1_000_000, 2)),\n",
    "                              ('median_salary_million', lambda x: round(np.median(x) / 1_000_000, 2)),\n",
    "                              ('std_salary_million', lambda x: round(x.std() / 1_000_000, 2)),\n",
    "                              ('min_salary_million', lambda x: round(x.min() / 1_000_000, 2)),\n",
    "                              ('max_salary_million', lambda x: round(x.max() / 1_000_000, 2)),\n",
    "                              ('count', 'count')])\n",
    "                        .reset_index())\n",
    "    \n",
    "        return salary_stats\n",
    "\n",
    "        \n",
    "    def retention_analysis(self):\n",
    "        current_date = datetime.now()\n",
    "    \n",
    "        df = self.employees_df.copy()\n",
    "        df['hire_date'] = pd.to_datetime(df['hire_date'])\n",
    "        df['tenure_years'] = ((current_date - df['hire_date']).dt.days / 365.25).round(2)\n",
    "    \n",
    "        merged_df = pd.merge(df,\n",
    "                             self.departments_df,\n",
    "                             on='department_id')\n",
    "    \n",
    "        retention_stats = (merged_df\n",
    "                           .groupby('department_name')['tenure_years']\n",
    "                           .agg([('mean_tenure', lambda x: round(x.mean(), 2)),\n",
    "                                 ('median_tenure', lambda x: round(np.median(x), 2)),\n",
    "                                 ('std_tenure', lambda x: round(x.std(), 2)),\n",
    "                                 ('employee_count', 'count')])\n",
    "                           .reset_index())\n",
    "    \n",
    "        return retention_stats\n",
    "    \n",
    "    \n",
    "    def training_effectiveness(self):\n",
    "        latest_performance = (self.performance_df\n",
    "                              .sort_values('review_date')\n",
    "                              .drop_duplicates('employee_id', keep='last'))\n",
    "    \n",
    "        merged_data = pd.merge(self.training_df,\n",
    "                               latest_performance[['employee_id', 'rating']],\n",
    "                               on='employee_id')\n",
    "    \n",
    "        effectiveness = (merged_data\n",
    "                         .groupby('training_name')\n",
    "                         .agg(avg_score=('score', 'mean'),\n",
    "                              avg_rating=('rating', 'mean'),\n",
    "                              participants_count=('employee_id', 'count'))\n",
    "                         .round(2)\n",
    "                         .reset_index())\n",
    "    \n",
    "        return effectiveness\n",
    "\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        # hitung tenure\n",
    "        df = self.employees_df.copy()\n",
    "        df['hire_date'] = pd.to_datetime(df['hire_date'])\n",
    "        current_date = datetime.now()\n",
    "        df['tenure_years'] = ((current_date - df['hire_date']).dt.days / 365.25).round(2)\n",
    "    \n",
    "        # join untuk hitung jumlah departemen unik\n",
    "        merged_df = pd.merge(df, self.departments_df, on='department_id')\n",
    "    \n",
    "        comprehensive_report = {\n",
    "            'turnover_rate': self.calculate_turnover_rate(),\n",
    "            'department_performance': self.analyze_department_performance(),\n",
    "            'attendance_stats': self.attendance_analysis(),\n",
    "            'salary_analysis': self.salary_analysis(),\n",
    "            'retention_analysis': self.retention_analysis(),\n",
    "            'training_effectiveness': self.training_effectiveness(),\n",
    "            'employee_summary': {\n",
    "                'total_employees': len(df),\n",
    "                'active_employees': len(df[df['status'] == 'active']),\n",
    "                'departments_count': merged_df['department_name'].nunique(),\n",
    "                'average_salary': f\"Rp {df['salary'].mean():,.0f}\",\n",
    "                'average_tenure': f\"{df['tenure_years'].mean():.1f} years\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        return comprehensive_report\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"Visualization\"\"\"\n",
    "    def plot_turnover_by_department(self):\n",
    "        merged = pd.merge(self.employees_df, self.departments_df,\n",
    "                          on='department_id', how='left')\n",
    "    \n",
    "        # Hitung turnover rate: % karyawan tidak aktif\n",
    "        turnover_by_dept = (merged.groupby('department_name')['status']\n",
    "                            .apply(lambda x: (x != 'active').mean() * 100)\n",
    "                            .round(2))\n",
    "    \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        turnover_by_dept.sort_values().plot(kind='bar', color='skyblue')\n",
    "        plt.title('Turnover Rate by Department')\n",
    "        plt.xlabel('Department')\n",
    "        plt.ylabel('Turnover Rate (%)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_salary_distribution(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Salinan df untuk jaga data asli\n",
    "        emp_df = self.employees_df.copy()\n",
    "        emp_df['salary_million'] = emp_df['salary'] / 1_000_000\n",
    "    \n",
    "        # Distribusi salary\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(emp_df['salary_million'], bins=20, kde=True, color='skyblue')\n",
    "        plt.title('Salary Distribution (in millions)')\n",
    "        plt.xlabel('Salary (Million IDR)')\n",
    "    \n",
    "        # Rata-rata salary per department\n",
    "        merged_df = pd.merge(emp_df, self.departments_df, on='department_id', how='left')\n",
    "        salary_by_dept = (merged_df.groupby('department_name')['salary_million']\n",
    "                          .mean()\n",
    "                          .sort_values())\n",
    "    \n",
    "        plt.subplot(1, 2, 2)\n",
    "        salary_by_dept.plot(kind='bar', color='lightgreen')\n",
    "        plt.title('Average Salary by Department')\n",
    "        plt.xlabel('Department')\n",
    "        plt.ylabel('Average Salary (Million IDR)')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_performance_trends(self):\n",
    "        merged_df = pd.merge(self.performance_df, self.employees_df, on='employee_id')\n",
    "        merged_df = pd.merge(merged_df, self.departments_df, on='department_id')\n",
    "    \n",
    "        # Tambah kolom tahun dari review_date\n",
    "        merged_df['year'] = pd.to_datetime(merged_df['review_date']).dt.year\n",
    "    \n",
    "        # Hitung rata-rata rating per tahun per department\n",
    "        performance_trend = (merged_df.groupby(['year', 'department_name'])['rating']\n",
    "                             .mean()\n",
    "                             .reset_index()\n",
    "                             .pivot(index='year', columns='department_name', values='rating'))\n",
    "    \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        performance_trend.plot(marker='o')\n",
    "        plt.title('Performance Rating Trend by Department')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Average Rating')\n",
    "        plt.legend(title='Department')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_attendance_patterns(self):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Attendance by day of week\n",
    "        self.attendance_df['day_of_week'] = pd.to_datetime(self.attendance_df['date']).dt.day_name()\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    \n",
    "        plt.subplot(2, 2, 1)\n",
    "        attendance_by_day = self.attendance_df['day_of_week'].value_counts().reindex(day_order)\n",
    "        attendance_by_day.plot(kind='bar', color='lightblue')\n",
    "        plt.title('Attendance by Day of Week')\n",
    "        plt.xlabel('Day')\n",
    "        plt.ylabel('Count')\n",
    "    \n",
    "        # Attendance status distribution\n",
    "        plt.subplot(2, 2, 2)\n",
    "        status_counts = self.attendance_df['status'].value_counts()\n",
    "        plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n",
    "        plt.title('Attendance Status Distribution')\n",
    "    \n",
    "        # Average hours by department\n",
    "        plt.subplot(2, 2, 3)\n",
    "        merged_attendance = pd.merge(self.attendance_df, self.employees_df, on='employee_id')\n",
    "        merged_attendance = pd.merge(merged_attendance, self.departments_df, on='department_id')\n",
    "    \n",
    "        hours_by_dept = (merged_attendance.groupby('department_name')['hours_worked']\n",
    "                         .mean()\n",
    "                         .sort_values())\n",
    "    \n",
    "        hours_by_dept.plot(kind='bar', color='orange')\n",
    "        plt.title('Average Hours Worked by Department')\n",
    "        plt.xlabel('Department')\n",
    "        plt.ylabel('Average Hours')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the model\n",
    "hr_model = HRAnalyticsModel()\n",
    "\n",
    "# Generate comprehensive report\n",
    "report = hr_model.generate_comprehensive_report()\n",
    "\n",
    "print(\"=== HR ANALYTICS REPORT ===\")\n",
    "print(f\"Total Employees: {report['employee_summary']['total_employees']}\")\n",
    "print(f\"Active Employees: {report['employee_summary']['active_employees']}\")\n",
    "print(f\"Turnover Rate: {report['turnover_rate']}%\")\n",
    "print(f\"\\nAverage Salary: {report['employee_summary']['average_salary']}\")\n",
    "print(f\"Average Tenure: {report['employee_summary']['average_tenure']}\")\n",
    "\n",
    "print(\"\\n=== DEPARTMENT PERFORMANCE ===\")\n",
    "print(report['department_performance'])\n",
    "\n",
    "print(\"\\n=== ATTENDANCE STATS ===\")\n",
    "for key, value in report['attendance_stats'].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Generate visualizations\n",
    "hr_model.plot_turnover_by_department()\n",
    "hr_model.plot_salary_distribution()\n",
    "hr_model.plot_performance_trends()\n",
    "hr_model.plot_attendance_patterns()\n",
    "\n",
    "# Access raw dataframes if needed\n",
    "print(\"\\nSample of employees data:\")\n",
    "print(hr_model.employees_df.head())\n",
    "print(f\"\\nShape of attendance data: {hr_model.attendance_df.shape}\")"
   ],
   "id": "b738c63aabd238ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Inheritance Structure\n",
    "#### Call constructor parent\n",
    "#### Dictionary for saving ML model\n",
    "```python\n",
    "class HRPredictiveModel(HRAnalyticsModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ml_models = {}\n",
    "```\n",
    "##### Explanation: A class that inherits all functionality from HRAnalyticsModel and adds machine learning capabilities\n",
    "\n",
    "## 2. Feature Engineering (prepare_features_for_ml)\n",
    "```python\n",
    "def prepare_features_for_ml(self):\n",
    "    features_df = self.employees_df.copy()\n",
    "```\n",
    "#### A. Numerical Feature Engineering:\n",
    "##### Years worked & Handle missing values\n",
    "```python\n",
    "features_df['tenure'] = (datetime.now() - pd.to_datetime(features_df['hire_date'])).dt.days / 365.25\n",
    "features_df['tenure'] = features_df['tenure'].fillna(0)\n",
    "```\n",
    "##### Salary normalization gaji (0-1)\n",
    "```python\n",
    "features_df['salary_normalized'] = features_df['salary'] / features_df['salary'].max()\n",
    "features_df['salary_normalized'] = features_df['salary_normalized'].fillna(0)\n",
    "```\n",
    "#### B. Performance Data Aggregation:\n",
    "##### Aggregate data performance per employee\n",
    "```python\n",
    "perf_agg = self.performance_df.groupby('employee_id')['rating'].agg(['mean', 'std', 'count']).reset_index()\n",
    "perf_agg.columns = ['employee_id', 'performance_mean', 'performance_std', 'performance_count']\n",
    "```\n",
    "##### Merge with main data\n",
    "```python\n",
    "features_df = features_df.merge(perf_agg, on='employee_id', how='left')\n",
    "```\n",
    "##### Handle missing values\n",
    "```python\n",
    "features_df['performance_mean'] = features_df['performance_mean'].fillna(features_df['performance_mean'].median())\n",
    "features_df['performance_std'] = features_df['performance_std'].fillna(0)\n",
    "features_df['performance_count'] = features_df['performance_count'].fillna(0)\n",
    "```\n",
    "#### C. Attendance Data Aggregation:\n",
    "##### Aggregate data attendance (Average working hours and attendance rate (0-1))\n",
    "```python\n",
    "attendance_agg = self.attendance_df.groupby('employee_id').agg({\n",
    "    'hours_worked': 'mean',\n",
    "    'status': lambda x: (x == 'absent').mean()\n",
    "})\n",
    "```\n",
    "#### D. Categorical Data Encoding:\n",
    "##### Convert department ke one-hot encoding\n",
    "```python\n",
    "if 'department' in features_df.columns:\n",
    "    features_df = pd.get_dummies(features_df, columns=['department'], prefix='dept')\n",
    "```\n",
    "##### Convert job title ke one-hot encoding\n",
    "```python\n",
    "if 'job_title' in features_df.columns:\n",
    "    features_df = pd.get_dummies(features_df, columns=['job_title'], prefix='job')\n",
    "```\n",
    "## 3. Dataset Preparation (create_turnover_prediction_dataset)\n",
    "##### Get engineered features\n",
    "```python\n",
    "def create_turnover_prediction_dataset(self):\n",
    "    features_df = self.prepare_features_for_ml()\n",
    "```\n",
    "#### A. Label Creation:\n",
    "##### Create target variable (label) with 1 = resigned, 0 = active\n",
    "```python\n",
    "y = (features_df['status'] != 'active').astype(int)\n",
    "print(f\"Label value counts: {y.value_counts().to_dict()}\")\n",
    "```\n",
    "#### B. Feature Selection:\n",
    "##### Drop columns that are not needed for training\n",
    "\n",
    "```python\n",
    "columns_to_drop = ['employee_id', 'first_name', 'last_name', 'email', 'hire_date', 'status']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]\n",
    "\n",
    "X = features_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "```\n",
    "##### Ensure will_resign doesn't exist (if it does)\n",
    "```python\n",
    "if 'will_resign' in X.columns:\n",
    "    X = X.drop('will_resign', axis=1)\n",
    "```\n",
    "## 4. Model Training (train_turnover_prediction_model)\n",
    "##### Get features and labels\n",
    "```python\n",
    "def train_turnover_prediction_model(self):\n",
    "    X, y = self.create_turnover_prediction_dataset()\n",
    "```\n",
    "#### A. Data Preprocessing:\n",
    "##### Save features name\n",
    "##### Handle missing values with median imputation\n",
    "```python\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "```\n",
    "#### B. Train-Test Split:\n",
    "##### Split data 80-20 with stratification\n",
    "##### stratify=y for Maintain class distribution\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "```\n",
    "#### C. Model Training:\n",
    "##### Use the Random Forest classifier\n",
    "##### Training\n",
    "```python\n",
    "model = RandomForestClassifier(n_estimators=100,\n",
    "                               random_state=42,\n",
    "                               class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "#### D. Model Evaluation:\n",
    "##### Predict dan evaluate\n",
    "##### Detailing metrics\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "#### E. Model Storage:\n",
    "##### Save models dan preprocessing components\n",
    "```python\n",
    "model.feature_names_ = feature_names\n",
    "self.ml_models['turnover_prediction'] = model\n",
    "self.ml_models['imputer'] = imputer\n",
    "self.ml_models['feature_names'] = feature_names\n",
    "```\n",
    "## 5. Prediction (predict_turnover_risk)\n",
    "##### Auto-train if the model doesn't exist yet\n",
    "```python\n",
    "def predict_turnover_risk(self, employee_id=None):\n",
    "    if 'turnover_prediction' not in self.ml_models:\n",
    "        self.train_turnover_prediction_model()\n",
    "```\n",
    "#### A. Feature Preparation for Prediction:\n",
    "##### Prepare features in the same way as training.\n",
    "```python\n",
    "features_df = self.prepare_features_for_ml()\n",
    "columns_to_drop = ['employee_id', 'first_name', 'last_name', 'email', 'hire_date', 'status']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]\n",
    "\n",
    "X_all = features_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "```\n",
    "#### B. Feature Alignment:\n",
    "##### Ensure features match training\n",
    "##### Handle missing features with loop and zero\n",
    "##### Handle extra features and discard unnecessary ones\n",
    "##### Sort features according to training\n",
    "```python\n",
    "feature_names = self.ml_models['feature_names']\n",
    "missing_features = set(feature_names) - set(X_all.columns)\n",
    "\n",
    "for feature in missing_features:\n",
    "    X_all[feature] = 0\n",
    "\n",
    "extra_features = set(X_all.columns) - set(feature_names)\n",
    "X_all = X_all.drop(list(extra_features), axis=1)\n",
    "X_all = X_all[feature_names]\n",
    "```\n",
    "#### C. Prediction:\n",
    "##### Preprocessing dan prediction\n",
    "##### Apply imputer\n",
    "##### Probability class 1\n",
    "##### Format results\n",
    "```python\n",
    "X_all_imputed = self.ml_models['imputer'].transform(X_all)\n",
    "predictions = self.ml_models['turnover_prediction'].predict_proba(X_all_imputed)[:, 1]\n",
    "\n",
    "results['turnover_risk'] = (predictions * 100).round(2)\n",
    "```\n",
    "## 6. Feature Importance Analysis\n",
    "##### Get importance scores from the model & Importance scores from Random Forest\n",
    "```python\n",
    "def analyze_feature_importance(self):\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': model.feature_names_,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "```\n",
    "## Engineered Key Features:\n",
    "- tenure - Years of service\n",
    "- salary_normalized - Normalized salary (0-1)\n",
    "- performance_mean - Average performance rating\n",
    "- performance_std - Performance consistency\n",
    "- avg_hours_worked - Average working hours\n",
    "- absence_rate - Absence rate (0-1)\n",
    "- One-hot encoded departments - dept_IT, dept_HR, etc.\n",
    "- One-hot encoded job titles - job_Manager, job_Analyst, etc.\n",
    "\n",
    "## Algorithms Used:\n",
    "- Random Forest - Robust ensemble method for classification\n",
    "- Class Weight Balancing - Handle imbalance between active vs resigned\n",
    "- Median Imputation - Handle missing values\n",
    "- Stratified Sampling - Maintain class distribution in split"
   ],
   "id": "c27684608274d77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:03:35.523654Z",
     "start_time": "2025-09-02T17:03:35.489237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Sample ML turnover prediction\"\"\"\n",
    "class HRPredictiveModel(HRAnalyticsModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ml_models = {}\n",
    "\n",
    "    def prepare_features_for_ml(self):\n",
    "        features_df = self.employees_df.copy()\n",
    "\n",
    "        # Feature engineering - make sure handle missing values\n",
    "        features_df['tenure'] = (datetime.now() - pd.to_datetime(features_df['hire_date'])).dt.days / 365.25\n",
    "        features_df['tenure'] = features_df['tenure'].fillna(0)\n",
    "\n",
    "        features_df['salary_normalized'] = features_df['salary'] / features_df['salary'].max()\n",
    "        features_df['salary_normalized'] = features_df['salary_normalized'].fillna(0)\n",
    "\n",
    "        # Aggregate performance data\n",
    "        perf_agg = self.performance_df.groupby('employee_id')['rating'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        perf_agg.columns = ['employee_id', 'performance_mean', 'performance_std', 'performance_count']\n",
    "\n",
    "        features_df = features_df.merge(perf_agg, on='employee_id', how='left')\n",
    "\n",
    "        # Fill missing performance values\n",
    "        features_df['performance_mean'] = features_df['performance_mean'].fillna(features_df['performance_mean'].median())\n",
    "        features_df['performance_std'] = features_df['performance_std'].fillna(0)\n",
    "        features_df['performance_count'] = features_df['performance_count'].fillna(0)\n",
    "\n",
    "        # Aggregate attendance data\n",
    "        if not self.attendance_df.empty:\n",
    "            attendance_agg = self.attendance_df.groupby('employee_id').agg({\n",
    "                'hours_worked': 'mean',\n",
    "                'status': lambda x: (x == 'absent').mean()  # absence rate\n",
    "            }).reset_index()\n",
    "            attendance_agg.columns = ['employee_id', 'avg_hours_worked', 'absence_rate']\n",
    "            features_df = features_df.merge(attendance_agg, on='employee_id', how='left')\n",
    "\n",
    "            # Fill missing attendance values\n",
    "            features_df['avg_hours_worked'] = features_df['avg_hours_worked'].fillna(features_df['avg_hours_worked'].median())\n",
    "            features_df['absence_rate'] = features_df['absence_rate'].fillna(0)\n",
    "\n",
    "        else:\n",
    "            features_df['avg_hours_worked'] = 8.0  # default value\n",
    "            features_df['absence_rate'] = 0.0\n",
    "\n",
    "        # Convert categorical variables - make sure existing columns\n",
    "        if 'department' in features_df.columns:\n",
    "            features_df = pd.get_dummies(features_df, columns=['department'], prefix='dept')\n",
    "\n",
    "        if 'job_title' in features_df.columns:\n",
    "            features_df = pd.get_dummies(features_df, columns=['job_title'], prefix='job')\n",
    "\n",
    "        return features_df\n",
    "\n",
    "    def create_turnover_prediction_dataset(self):\n",
    "        features_df = self.prepare_features_for_ml()\n",
    "\n",
    "        if 'status' not in features_df.columns:\n",
    "            print(\"Error: 'status' column not found in features_df\")\n",
    "            return None, None\n",
    "\n",
    "        y = (features_df['status'] != 'active').astype(int)\n",
    "        print(f\"Label value counts: {y.value_counts().to_dict()}\")\n",
    "        columns_to_drop = ['employee_id', 'first_name', 'last_name', 'email', 'hire_date', 'status']\n",
    "        columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]\n",
    "        x = features_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "        if 'will_resign' in x.columns:\n",
    "            x = x.drop('will_resign', axis=1)\n",
    "\n",
    "        print(f\"X columns: {x.columns.tolist()}\")\n",
    "        print(f\"X shape: {x.shape}, y shape: {y.shape}\")\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def train_turnover_prediction_model(self):\n",
    "        try:\n",
    "            x, y = self.create_turnover_prediction_dataset()\n",
    "    \n",
    "            if x is None or y is None:\n",
    "                print(\"Failed to create dataset\")\n",
    "                return None\n",
    "    \n",
    "            # Simpan nama fitur mentah (urutan asli)\n",
    "            feature_names_raw = x.columns.tolist()\n",
    "    \n",
    "            # Tentukan fitur numerik & kategorikal secara dinamis\n",
    "            numeric_features = x.select_dtypes(include=['number']).columns.tolist()\n",
    "            categorical_features = x.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "    \n",
    "            print(f\"Raw feature names: {feature_names_raw}\")\n",
    "            print(f\"Numeric features: {numeric_features}\")\n",
    "            print(f\"Categorical features: {categorical_features}\")\n",
    "    \n",
    "            # Buat transformer hanya untuk grup yang tidak kosong\n",
    "            transformers = []\n",
    "            if numeric_features:\n",
    "                numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median'))])\n",
    "                transformers.append(('num', numeric_transformer, numeric_features))\n",
    "    \n",
    "            if categorical_features:\n",
    "                categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                                          ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "                \n",
    "                transformers.append(('cat', categorical_transformer, categorical_features))\n",
    "    \n",
    "            preprocessor = ColumnTransformer(transformers=transformers, remainder='drop')\n",
    "    \n",
    "            # Pipeline utama: preprocessing + classifier\n",
    "            pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                       ('classifier', RandomForestClassifier(n_estimators=100,\n",
    "                                                                             random_state=42,\n",
    "                                                                             class_weight='balanced'))])\n",
    "    \n",
    "            # Split (pakai x mentah — pipeline akan meng-handle impute/encode)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                                y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=42,\n",
    "                                                                stratify=y)\n",
    "    \n",
    "            # Fit pipeline\n",
    "            pipeline.fit(x_train, y_train)\n",
    "    \n",
    "            # Evaluasi\n",
    "            y_pred = pipeline.predict(x_test)\n",
    "            print(\"Model Evaluation:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "    \n",
    "            # --- Attach atribut yang dibutuhkan oleh cell test ---\n",
    "            # feature_names_ -> raw feature names (sama seperti X.columns saat training)\n",
    "            pipeline.feature_names_ = feature_names_raw\n",
    "            transformed_feature_names = []\n",
    "            \n",
    "            if numeric_features:\n",
    "                transformed_feature_names.extend(numeric_features)\n",
    "    \n",
    "            if categorical_features:\n",
    "                # akses encoder setelah fit\n",
    "                try:\n",
    "                    cat_transformer = preprocessor.named_transformers_['cat']\n",
    "                    # cat_transformer adalah Pipeline; ambil step encoder\n",
    "                    encoder = cat_transformer.named_steps.get('encoder', cat_transformer)\n",
    "                    \n",
    "                    # dapatkan nama fitur hasil encode\n",
    "                    try:\n",
    "                        cat_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "                        \n",
    "                    except AttributeError:\n",
    "                        # fallback untuk sklearn lama\n",
    "                        cat_feature_names = encoder.get_feature_names(categorical_features)\n",
    "                        \n",
    "                    transformed_feature_names.extend(list(cat_feature_names))\n",
    "                    \n",
    "                except Exception:\n",
    "                    # kalau tidak ada fitur kategorikal atau encoder gagal,\n",
    "                    # biarkan transformed_feature_names seperti numeric saja\n",
    "                    pass\n",
    "    \n",
    "            pipeline.transformed_feature_names_ = transformed_feature_names\n",
    "    \n",
    "            # Simpan model & metadata ke self.ml_models\n",
    "            self.ml_models['turnover_prediction'] = pipeline\n",
    "            self.ml_models['feature_names'] = feature_names_raw\n",
    "            self.ml_models['transformed_feature_names'] = transformed_feature_names\n",
    "    \n",
    "            # Jika classifier punya feature_importances_, map ke nama fitur ter-transform\n",
    "            clf = pipeline.named_steps['classifier']\n",
    "            if hasattr(clf, 'feature_importances_') and len(transformed_feature_names) == len(clf.feature_importances_):\n",
    "                fi = pd.DataFrame({\n",
    "                    'feature': transformed_feature_names,\n",
    "                    'importance': clf.feature_importances_\n",
    "                }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "                self.ml_models['feature_importances'] = fi\n",
    "                \n",
    "            else:\n",
    "                # Bila ukurannya mismatch (mis. tidak ada fitur kategorikal, dsb.), coba partial mapping atau skip\n",
    "                self.ml_models['feature_importances'] = None\n",
    "    \n",
    "            print(f\"Model trained successfully with {len(feature_names_raw)} raw features \"\n",
    "                  f\"and {len(transformed_feature_names)} transformed features.\")\n",
    "    \n",
    "            return pipeline\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error training model: {e}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            return None\n",
    "\n",
    "    def predict_turnover_risk(self):\n",
    "        try:\n",
    "            if 'turnover_prediction' not in self.ml_models:\n",
    "                print(\"Training model first...\")\n",
    "                self.train_turnover_prediction_model()\n",
    "    \n",
    "                if 'turnover_prediction' not in self.ml_models:\n",
    "                    return None\n",
    "    \n",
    "            features_df = self.prepare_features_for_ml()\n",
    "    \n",
    "            # Drop kolom non-feature\n",
    "            columns_to_drop = ['employee_id', 'first_name', 'last_name', 'email', 'hire_date', 'status']\n",
    "            columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]\n",
    "    \n",
    "            x_all = features_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "    \n",
    "            if 'will_resign' in x_all.columns:\n",
    "                x_all = x_all.drop('will_resign', axis=1)\n",
    "    \n",
    "            feature_names = self.ml_models['feature_names']\n",
    "            print(f\"Expected features: {feature_names}\")\n",
    "            print(f\"Available features: {x_all.columns.tolist()}\")\n",
    "    \n",
    "            # Sesuaikan kolom dengan training\n",
    "            missing_features = set(feature_names) - set(x_all.columns)\n",
    "            extra_features = set(x_all.columns) - set(feature_names)\n",
    "    \n",
    "            if missing_features:\n",
    "                print(f\"Warning: Missing features {missing_features}, filling with 0\")\n",
    "                for feature in missing_features:\n",
    "                    x_all[feature] = 0\n",
    "    \n",
    "            if extra_features:\n",
    "                print(f\"Warning: Dropping extra features {extra_features}\")\n",
    "                x_all = x_all.drop(list(extra_features), axis=1)\n",
    "    \n",
    "            # Urutkan sesuai training\n",
    "            x_all = x_all[feature_names]\n",
    "    \n",
    "            # langsung pakai pipeline (tidak perlu imputer manual)\n",
    "            predictions = self.ml_models['turnover_prediction'].predict_proba(x_all)[:, 1]\n",
    "    \n",
    "            results = features_df[['employee_id', 'first_name', 'last_name']].copy()\n",
    "    \n",
    "            # Add department jika ada\n",
    "            if 'department' in features_df.columns:\n",
    "                results['department'] = features_df['department']\n",
    "                \n",
    "            elif 'dept_IT' in features_df.columns:  # contoh one-hot\n",
    "                dept_columns = [col for col in features_df.columns if col.startswith('dept_')]\n",
    "                \n",
    "                if dept_columns:\n",
    "                    results['department'] = features_df[dept_columns].idxmax(axis=1).str.replace('dept_', '')\n",
    "    \n",
    "            results['turnover_risk'] = (predictions * 100).round(2)\n",
    "            results['status'] = features_df['status']\n",
    "    \n",
    "            return results.sort_values('turnover_risk', ascending=False)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting turnover risk: {e}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            return None\n",
    "\n",
    "\n",
    "    def analyze_feature_importance(self):\n",
    "        try:\n",
    "            if 'turnover_prediction' not in self.ml_models:\n",
    "                self.train_turnover_prediction_model()\n",
    "\n",
    "            model = self.ml_models['turnover_prediction']\n",
    "            x, _ = self.create_turnover_prediction_dataset()\n",
    "\n",
    "            feature_importances = pd.DataFrame({\n",
    "                'feature': model.feature_names_,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.barplot(data=feature_importances.head(10), x='importance', y='feature')\n",
    "            plt.title('Top 10 Features Affecting Employee Turnover')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            return feature_importances\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing feature importance: {e}\")\n",
    "\n",
    "            return None"
   ],
   "id": "8eea576dd3629bde",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:03:42.169429Z",
     "start_time": "2025-09-02T17:03:37.551453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing\n",
    "try:\n",
    "    hr_ml_model = HRPredictiveModel()\n",
    "    \n",
    "    print(\"=== TRAINING ===\")\n",
    "    ml_model = hr_ml_model.train_turnover_prediction_model()\n",
    "    \n",
    "    if ml_model is not None:\n",
    "        print(\"=== FEATURE VALIDATION ===\")\n",
    "        print(\"Model feature names:\", ml_model.feature_names_)\n",
    "        \n",
    "        # Prepare features untuk prediction\n",
    "        features_df = hr_ml_model.prepare_features_for_ml()\n",
    "        columns_to_drop = ['employee_id', 'first_name', 'last_name', 'email', 'hire_date', 'status']\n",
    "        columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]\n",
    "        X_pred = features_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "        \n",
    "        print(\"Prediction features:\", X_pred.columns.tolist())\n",
    "        print(\"Feature match:\", set(ml_model.feature_names_) == set(X_pred.columns))\n",
    "        \n",
    "        print(\"=== PREDICTION ===\")\n",
    "        risk_scores = hr_ml_model.predict_turnover_risk()\n",
    "        if risk_scores is not None:\n",
    "            print(\"\\nTop 10 employees with highest turnover risk:\")\n",
    "            print(risk_scores.head(10))\n",
    "            \n",
    "            # Analisis hasil\n",
    "            print(f\"\\nRisk score statistics:\")\n",
    "            print(f\"Min: {risk_scores['turnover_risk'].min():.2f}%\")\n",
    "            print(f\"Max: {risk_scores['turnover_risk'].max():.2f}%\")\n",
    "            print(f\"Avg: {risk_scores['turnover_risk'].mean():.2f}%\")\n",
    "            print(f\"Active employees avg risk: {risk_scores[risk_scores['status'] == 'active']['turnover_risk'].mean():.2f}%\")\n",
    "            print(f\"Resigned employees avg risk: {risk_scores[risk_scores['status'] == 'resigned']['turnover_risk'].mean():.2f}%\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    traceback.print_exc()"
   ],
   "id": "8b2f3d6949906a6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/dg0b0x211vx9yftt50b2n2lh0000gn/T/ipykernel_60294/3808025729.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, self.conn)\n",
      "/var/folders/p3/dg0b0x211vx9yftt50b2n2lh0000gn/T/ipykernel_60294/3808025729.py:54: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, self.conn)\n",
      "/var/folders/p3/dg0b0x211vx9yftt50b2n2lh0000gn/T/ipykernel_60294/3808025729.py:63: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, self.conn)\n",
      "/var/folders/p3/dg0b0x211vx9yftt50b2n2lh0000gn/T/ipykernel_60294/3808025729.py:72: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, self.conn)\n",
      "/var/folders/p3/dg0b0x211vx9yftt50b2n2lh0000gn/T/ipykernel_60294/3808025729.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, self.conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING ===\n",
      "Label value counts: {0: 160, 1: 40}\n",
      "X columns: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "X shape: (200, 32), y shape: (200,)\n",
      "Raw feature names: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "Numeric features: ['salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate']\n",
      "Categorical features: ['department_id', 'manager_id', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.94      0.98      0.96        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n",
      "Model trained successfully with 32 raw features and 64 transformed features.\n",
      "=== FEATURE VALIDATION ===\n",
      "Model feature names: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "Prediction features: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "Feature match: True\n",
      "=== PREDICTION ===\n",
      "Expected features: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "Available features: ['department_id', 'manager_id', 'salary', 'tenure', 'salary_normalized', 'performance_mean', 'performance_std', 'performance_count', 'avg_hours_worked', 'absence_rate', 'job_Account Manager', 'job_Accountant', 'job_Auditor', 'job_Business Development', 'job_Content Creator', 'job_Data Analyst', 'job_Finance Manager', 'job_Financial Analyst', 'job_HR Manager', 'job_HR Specialist', 'job_IT Manager', 'job_Logistics Coordinator', 'job_Marketing Manager', 'job_Marketing Specialist', 'job_Operations Manager', 'job_Recruiter', 'job_SEO Analyst', 'job_Sales Representative', 'job_Software Engineer', 'job_Supply Chain Specialist', 'job_System Admin', 'job_Training Coordinator']\n",
      "\n",
      "Top 10 employees with highest turnover risk:\n",
      "                              employee_id first_name  last_name  \\\n",
      "64   c4a3302d-6102-4f21-b54f-3bec5733510f     Rahman   Mahendra   \n",
      "188  8ab23084-7e62-4320-97d5-ca87a8ff0d89  Baktianto    Gunarto   \n",
      "130  00fe10ac-0aa4-42e8-9679-6874f266cb8f        Uda  Iswahyudi   \n",
      "98   58c6a2ef-6405-4fa5-88fd-2a299a2a6db1    Cinthia    Prabowo   \n",
      "142  d0f3c8ac-59c1-403c-b747-62c66270c829      Najib  Manullang   \n",
      "68   b7a04bad-4e62-43e2-98a7-0eb1b576c378       Anom    Hastuti   \n",
      "69   b57f219e-f81f-44ca-9b5f-5f27fd6195ad    Kuncara  Megantara   \n",
      "46   b1e9a7a9-a6ca-4a61-89b7-b5b062f9ca21    Hartaka  Megantara   \n",
      "27   7454fbce-64e0-4285-8cb4-63a35f5013cf        Ian    Narpati   \n",
      "70   9d2bc9ce-4aeb-483f-b4a7-23df99d841e0   Prayitna   Palastri   \n",
      "\n",
      "     turnover_risk      status  \n",
      "64           100.0    resigned  \n",
      "188          100.0  terminated  \n",
      "130          100.0    resigned  \n",
      "98           100.0  terminated  \n",
      "142          100.0    resigned  \n",
      "68            99.0    resigned  \n",
      "69            99.0  terminated  \n",
      "46            99.0    resigned  \n",
      "27            99.0    resigned  \n",
      "70            99.0    resigned  \n",
      "\n",
      "Risk score statistics:\n",
      "Min: 0.00%\n",
      "Max: 100.00%\n",
      "Avg: 20.29%\n",
      "Active employees avg risk: 1.58%\n",
      "Resigned employees avg risk: 94.39%\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class HRPredictiveResignedModel(HRAnalyticsModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ml_models = {}\n",
    "\n",
    "    def prepare_features(self):\n",
    "        # Attendance features\n",
    "        att_agg = self.attendance_df.groupby(\"employee_id\").agg({\n",
    "            \"hours_worked\": \"mean\",\n",
    "            \"status\": lambda x: (x == \"Absent\").sum() / len(x)\n",
    "        }).reset_index()\n",
    "        att_agg.rename(columns={\"hours_worked\": \"avg_hours\", \"status\": \"absent_ratio\"}, inplace=True)\n",
    "\n",
    "        # Performance features\n",
    "        perf_agg = self.performance_df.groupby(\"employee_id\")[\"rating\"].mean().reset_index()\n",
    "        perf_agg.rename(columns={\"rating\": \"avg_rating\"}, inplace=True)\n",
    "\n",
    "        # Training features\n",
    "        train_agg = self.training_df.groupby(\"employee_id\")[\"score\"].mean().reset_index()\n",
    "        train_agg.rename(columns={\"score\": \"avg_training_score\"}, inplace=True)\n",
    "\n",
    "        # Merge to employees\n",
    "        df = self.employees_df.merge(att_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(perf_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(train_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(self.departments_df, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        # Tenure\n",
    "        df[\"hire_date\"] = pd.to_datetime(df[\"hire_date\"])\n",
    "        df[\"tenure_days\"] = (pd.Timestamp.now() - df[\"hire_date\"]).dt.days\n",
    "\n",
    "        # Target\n",
    "        df[\"resigned\"] = df[\"status\"].apply(lambda x: 1 if str(x).lower() == \"resigned\" else 0)\n",
    "\n",
    "        # Bersihin NaN\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        X = df[[\"salary\", \"avg_hours\", \"absent_ratio\", \"avg_rating\", \n",
    "                \"avg_training_score\", \"tenure_days\", \"budget\"]]\n",
    "        y = df[\"resigned\"]\n",
    "\n",
    "        return X, y, df\n",
    "\n",
    "    def train_resignation_model(self):\n",
    "        X, y, _ = self.prepare_features()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        self.ml_models[\"resignation\"] = model\n",
    "\n",
    "    def predict_resignation_risk(self, employee_id):\n",
    "        if \"resignation\" not in self.ml_models:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "\n",
    "        X, _, df = self.prepare_features()\n",
    "        row = df[df[\"employee_id\"] == employee_id]\n",
    "\n",
    "        if row.empty:\n",
    "            return None\n",
    "\n",
    "        features = row[[\"salary\", \"avg_hours\", \"absent_ratio\", \"avg_rating\",\n",
    "                        \"avg_training_score\", \"tenure_days\", \"budget\"]]\n",
    "        prob = self.ml_models[\"resignation\"].predict_proba(features)[0][1]\n",
    "\n",
    "        return {\n",
    "            \"employee_id\": employee_id,\n",
    "            \"name\": f\"{row.iloc[0]['first_name']} {row.iloc[0]['last_name']}\",\n",
    "            \"resignation_risk\": prob,\n",
    "            \"impact_analysis\": {\n",
    "                \"salary_loss\": row.iloc[0][\"salary\"],\n",
    "                \"training_investment_loss\": row.iloc[0][\"avg_training_score\"] * 1000,\n",
    "                \"department_budget_share\": row.iloc[0][\"salary\"] / row.iloc[0][\"budget\"] if row.iloc[0][\"budget\"] > 0 else 0,\n",
    "                \"productivity_loss_hours\": row.iloc[0][\"avg_hours\"] * 22\n",
    "            }\n",
    "        }"
   ],
   "id": "d16ee4c0a12fd1ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    print(\"=== INIT MODEL ===\")\n",
    "    hr_ml_model = HRPredictiveResignedModel()\n",
    "\n",
    "    print(\"=== TRAINING ===\")\n",
    "    hr_ml_model.train_resignation_model()\n",
    "\n",
    "    if \"resignation\" in hr_ml_model.ml_models:\n",
    "        model = hr_ml_model.ml_models[\"resignation\"]\n",
    "\n",
    "        # Cek fitur yang dipakai model\n",
    "        X, y, df = hr_ml_model.prepare_features()\n",
    "        print(\"Model feature names:\", X.columns.tolist())\n",
    "        print(\"Prediction features:\", X.columns.tolist())\n",
    "        print(\"Feature match:\", set(model.feature_names_in_) == set(X.columns))\n",
    "\n",
    "        print(\"=== PREDICTION (contoh 10 pegawai) ===\")\n",
    "        sample_employees = df[\"employee_id\"].sample(10, random_state=42).tolist()\n",
    "        \n",
    "        for emp_id in sample_employees:\n",
    "            result = hr_ml_model.predict_resignation_risk(emp_id)\n",
    "            \n",
    "            if result:\n",
    "                print(result)\n",
    "\n",
    "        # Analisis agregat\n",
    "        print(\"\\n=== STATISTICS ===\")\n",
    "        preds = []\n",
    "        \n",
    "        for emp_id in df[\"employee_id\"].tolist():\n",
    "            result = hr_ml_model.predict_resignation_risk(emp_id)\n",
    "            \n",
    "            if result:\n",
    "                preds.append({\n",
    "                    \"employee_id\": emp_id,\n",
    "                    \"status\": df[df[\"employee_id\"] == emp_id][\"status\"].values[0],\n",
    "                    \"risk\": result[\"resignation_risk\"]\n",
    "                })\n",
    "\n",
    "        preds_df = pd.DataFrame(preds)\n",
    "        print(f\"Min risk: {preds_df['risk'].min():.2f}\")\n",
    "        print(f\"Max risk: {preds_df['risk'].max():.2f}\")\n",
    "        print(f\"Avg risk: {preds_df['risk'].mean():.2f}\")\n",
    "        print(f\"Active employees avg risk: {preds_df[preds_df['status'].str.lower() == 'active']['risk'].mean():.2f}\")\n",
    "        print(f\"Resigned employees avg risk: {preds_df[preds_df['status'].str.lower() == 'resigned']['risk'].mean():.2f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    traceback.print_exc()\n"
   ],
   "id": "6a2cf813ff81a6ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class HRPredictivePromotionModel(HRAnalyticsModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ml_models = {}\n",
    "\n",
    "    def prepare_features(self):\n",
    "        # Attendance features\n",
    "        att_agg = self.attendance_df.groupby(\"employee_id\").agg({\n",
    "            \"hours_worked\": \"mean\",\n",
    "            \"status\": lambda x: (x == \"Absent\").sum() / len(x)\n",
    "        }).reset_index()\n",
    "        att_agg.rename(columns={\"hours_worked\": \"avg_hours\", \"status\": \"absent_ratio\"}, inplace=True)\n",
    "\n",
    "        # Performance features\n",
    "        perf_agg = self.performance_df.groupby(\"employee_id\")[\"rating\"].mean().reset_index()\n",
    "        perf_agg.rename(columns={\"rating\": \"avg_rating\"}, inplace=True)\n",
    "\n",
    "        # Training features\n",
    "        train_agg = self.training_df.groupby(\"employee_id\")[\"score\"].mean().reset_index()\n",
    "        train_agg.rename(columns={\"score\": \"avg_training_score\"}, inplace=True)\n",
    "\n",
    "        # Merge ke employees\n",
    "        df = self.employees_df.merge(att_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(perf_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(train_agg, on=\"employee_id\", how=\"left\") \\\n",
    "                              .merge(self.departments_df, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        # Tenure\n",
    "        df[\"hire_date\"] = pd.to_datetime(df[\"hire_date\"])\n",
    "        df[\"tenure_days\"] = (pd.Timestamp.now() - df[\"hire_date\"]).dt.days\n",
    "\n",
    "        # Label promotion (rule sederhana, bisa diubah sesuai data real)\n",
    "        df[\"promoted\"] = df[\"job_title\"].str.lower().apply(\n",
    "            lambda x: 1 if (\"senior\" in x or \"manager\" in x or \"head\" in x) else 0\n",
    "        )\n",
    "\n",
    "        # Bersihin NaN\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        # Features\n",
    "        X = df[[\"salary\", \"avg_hours\", \"absent_ratio\", \"avg_rating\", \n",
    "                \"avg_training_score\", \"tenure_days\", \"budget\"]]\n",
    "        y = df[\"promoted\"]\n",
    "\n",
    "        return X, y, df\n",
    "\n",
    "    def train_promotion_model(self):\n",
    "        X, y, _ = self.prepare_features()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        self.ml_models[\"promotion\"] = model\n",
    "\n",
    "    def predict_promotion_probability(self, employee_id):\n",
    "        if \"promotion\" not in self.ml_models:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "\n",
    "        X, _, df = self.prepare_features()\n",
    "        row = df[df[\"employee_id\"] == employee_id]\n",
    "\n",
    "        if row.empty:\n",
    "            return None\n",
    "\n",
    "        features = row[[\"salary\", \"avg_hours\", \"absent_ratio\", \"avg_rating\",\n",
    "                        \"avg_training_score\", \"tenure_days\", \"budget\"]]\n",
    "        prob = self.ml_models[\"promotion\"].predict_proba(features)[0][1]\n",
    "\n",
    "        return {\n",
    "            \"employee_id\": employee_id,\n",
    "            \"name\": f\"{row.iloc[0]['first_name']} {row.iloc[0]['last_name']}\",\n",
    "            \"promotion_probability\": prob,\n",
    "            \"factors\": {\n",
    "                \"salary\": row.iloc[0][\"salary\"],\n",
    "                \"avg_rating\": row.iloc[0][\"avg_rating\"],\n",
    "                \"training_score\": row.iloc[0][\"avg_training_score\"],\n",
    "                \"tenure_days\": row.iloc[0][\"tenure_days\"],\n",
    "                \"absent_ratio\": row.iloc[0][\"absent_ratio\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def predict_all_promotions(self):\n",
    "        if \"promotion\" not in self.ml_models:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "\n",
    "        X, _, df = self.prepare_features()\n",
    "        probs = self.ml_models[\"promotion\"].predict_proba(X)[:, 1]\n",
    "\n",
    "        df_result = df.copy()\n",
    "        df_result[\"promotion_probability\"] = probs\n",
    "\n",
    "        # Urutkan dari kandidat paling besar peluangnya\n",
    "        df_result = df_result.sort_values(by=\"promotion_probability\", ascending=False)\n",
    "\n",
    "        return df_result[[\n",
    "            \"employee_id\", \"first_name\", \"last_name\", \"department_name\", \"job_title\", \n",
    "            \"salary\", \"avg_rating\", \"avg_training_score\", \"tenure_days\", \n",
    "            \"promotion_probability\"\n",
    "        ]]"
   ],
   "id": "f6ac59084a3172c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    print(\"=== INIT MODEL ===\")\n",
    "    hr_promo_model = HRPredictivePromotionModel()\n",
    "\n",
    "    print(\"=== TRAINING ===\")\n",
    "    hr_promo_model.train_promotion_model()\n",
    "\n",
    "    if \"promotion\" in hr_promo_model.ml_models:\n",
    "        print(\"\\n=== PREDICT ONE EMPLOYEE ===\")\n",
    "\n",
    "        # ambil 1 random employee dari dataset\n",
    "        _, _, df = hr_promo_model.prepare_features()\n",
    "        sample_emp = df.sample(1, random_state=42).iloc[0][\"employee_id\"]\n",
    "\n",
    "        result = hr_promo_model.predict_promotion_probability(sample_emp)\n",
    "        if result:\n",
    "            print(\"Prediction result:\")\n",
    "            print(result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    traceback.print_exc()\n"
   ],
   "id": "48084e2b41b8e928"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    print(\"=== INIT MODEL ===\")\n",
    "    hr_promo_model = HRPredictivePromotionModel()\n",
    "\n",
    "    print(\"=== TRAINING ===\")\n",
    "    hr_promo_model.train_promotion_model()\n",
    "\n",
    "    if \"promotion\" in hr_promo_model.ml_models:\n",
    "        print(\"\\n=== PREDICT ALL EMPLOYEES ===\")\n",
    "        results = hr_promo_model.predict_all_promotion_probabilities()\n",
    "\n",
    "        # tampilkan 5 hasil teratas untuk cek\n",
    "        for r in results[:5]:\n",
    "            print(r)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    traceback.print_exc()\n"
   ],
   "id": "cb5273002207e452"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
